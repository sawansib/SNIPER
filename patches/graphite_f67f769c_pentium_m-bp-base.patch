diff --git a/common/tile/core/branch_predictor.cc b/common/tile/core/branch_predictor.cc
index ad056b2..69c2364 100644
--- a/common/tile/core/branch_predictor.cc
+++ b/common/tile/core/branch_predictor.cc
@@ -1,6 +1,7 @@
 #include "simulator.h"
 #include "branch_predictor.h"
 #include "one_bit_branch_predictor.h"
+#include "pentium_m_branch_predictor.h"
 
 BranchPredictor::BranchPredictor()
 {
@@ -31,6 +32,10 @@ BranchPredictor* BranchPredictor::create()
          UInt32 size = cfg->getInt("perf_model/branch_predictor/size");
          return new OneBitBranchPredictor(size);
       }
+      else if (type == "pentium_m")
+      {
+         return new PentiumMBranchPredictor();
+      }
       else
       {
          LOG_PRINT_ERROR("Invalid branch predictor type.");
diff --git a/common/tile/core/branch_predictors/branch_predictor_return_value.cc b/common/tile/core/branch_predictors/branch_predictor_return_value.cc
new file mode 100644
index 0000000..8053986
--- /dev/null
+++ b/common/tile/core/branch_predictors/branch_predictor_return_value.cc
@@ -0,0 +1,17 @@
+//
+// branch_predictor_return_value.cc
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#include "branch_predictor_return_value.h"
+
+const char* BranchPredictorReturnValue::BranchTypeNames[] =
+   {
+      "InvalidBranch",
+      "DirectBranch",
+      "IndirectBranch",
+      "UnconditionalBranch",
+      "ConditionalBranch"
+   };
+
diff --git a/common/tile/core/branch_predictors/branch_predictor_return_value.h b/common/tile/core/branch_predictors/branch_predictor_return_value.h
new file mode 100644
index 0000000..5baa19e
--- /dev/null
+++ b/common/tile/core/branch_predictors/branch_predictor_return_value.h
@@ -0,0 +1,54 @@
+//
+// branch_predictor_return_value.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef BRANCH_PREDICTOR_RETURN_VALUE
+#define BRANCH_PREDICTOR_RETURN_VALUE
+
+#include <ostream>
+#include <ios>
+#include <boost/io/ios_state.hpp>
+
+#include "fixed_types.h"
+
+class BranchPredictorReturnValue {
+
+public:
+
+   enum BranchType
+   {
+      InvalidBranch = 0,
+      DirectBranch,
+      IndirectBranch,
+      UnconditionalBranch,
+      ConditionalBranch
+   };
+
+   static const char* BranchTypeNames[];
+
+   bool prediction;
+   bool hit;
+   IntPtr target;
+   BranchType type;
+
+   friend std::ostream& operator <<(std::ostream& stream, const BranchPredictorReturnValue& value);
+
+};
+
+inline std::ostream& operator <<(std::ostream& stream, const BranchPredictorReturnValue& value)
+{
+
+   boost::io::ios_flags_saver ifs(stream);
+
+   stream
+      << "Pred = " << value.prediction
+      << " Hit = " << value.hit
+      << " Tgt = " << std::hex << value.target << std::dec
+      << " Type = " << BranchPredictorReturnValue::BranchTypeNames[value.type];
+
+   return stream;
+}
+
+#endif /* BRANCH_PREDICTOR_RETURN_VALUE */
diff --git a/common/tile/core/branch_predictors/global_predictor.h b/common/tile/core/branch_predictors/global_predictor.h
new file mode 100644
index 0000000..1c88c85
--- /dev/null
+++ b/common/tile/core/branch_predictors/global_predictor.h
@@ -0,0 +1,142 @@
+//
+// global_predictor.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef GLOBAL_PREDICTOR_H
+#define GLOBAL_PREDICTOR_H
+
+#include <vector>
+#include <stdint.h>
+
+#include "simulator.h"
+#include "branch_predictor.h"
+#include "branch_predictor_return_value.h"
+#include "saturating_predictor.h"
+
+class GlobalPredictor : BranchPredictor
+{
+
+public:
+
+   GlobalPredictor(UInt32 entries, UInt32 tag_bitwidth, UInt32 ways)
+      : m_lru_use_count(0)
+      , m_num_ways(ways)
+      , m_ways(ways, Way(entries/ways, 6))
+   {
+   }
+
+   bool predict(IntPtr ip, IntPtr target)
+   {
+      UInt32 index, tag;
+
+      gen_index_tag(ip, index, tag);
+
+      for (unsigned int w = 0 ; w < m_num_ways ; ++w )
+      {
+         if (m_ways[w].m_tags[index] == tag)
+         {
+            return true;
+         }
+      }
+      return false;
+   }
+
+   BranchPredictorReturnValue lookup(IntPtr ip, IntPtr target)
+   {
+
+      UInt32 index, tag;
+      BranchPredictorReturnValue ret = { 0, 0, 0, BranchPredictorReturnValue::InvalidBranch };
+
+      gen_index_tag(ip, index, tag);
+
+      for (unsigned int w = 0 ; w < m_num_ways ; ++w )
+      {
+         if (m_ways[w].m_tags[index] == tag)
+         {
+            ret.hit = 1;
+            ret.prediction = m_ways[w].m_predictors[index].predict();
+            break;
+         }
+      }
+
+      return ret;
+   }
+
+   void update(bool predicted, bool actual, IntPtr ip, IntPtr target)
+   {
+
+      UInt32 index, tag, lru_way;
+
+      gen_index_tag(ip, index, tag);
+
+      // Start with way 0 as the least recently used
+      lru_way = 0;
+
+      for (unsigned int w = 0 ; w < m_num_ways ; ++w )
+      {
+         if (m_ways[w].m_tags[index] == tag)
+         {
+            m_ways[w].m_predictors[index].update(actual);
+            m_ways[w].m_lru[index] = m_lru_use_count++;
+            // Once we have a tag match and have updated the LRU information,
+            // we can return
+            return;
+         }
+
+         // Keep track of the LRU in case we do not have a tag match
+         if (m_ways[w].m_lru[index] < m_ways[lru_way].m_lru[index])
+         {
+            lru_way = w;
+         }
+      }
+
+      // We will get here only if we have not matched the tag
+      // If that is the case, select the LRU entry, and update the tag
+      // appropriately
+      m_ways[lru_way].m_tags[index] = tag;
+      // Here, we miss with the tag, so reset instead of updating
+      m_ways[lru_way].m_predictors[index].reset(actual);
+      m_ways[lru_way].m_lru[index] = m_lru_use_count++;
+
+   }
+
+private:
+
+   class Way
+   {
+   public:
+
+      Way(UInt32 entries, UInt32 tag_bitwidth)
+         : m_tags(entries, 0)
+         , m_predictors(entries, SaturatingPredictor<2>(0))
+         , m_lru(entries, 0)
+         , m_num_entries(entries)
+         , m_tag_bitwidth(tag_bitwidth)
+      {
+         assert(tag_bitwidth <= 8 && tag_bitwidth >= 0);
+      }
+
+      std::vector<uint8_t> m_tags;
+      std::vector<SaturatingPredictor<2> > m_predictors;
+      std::vector<UInt64> m_lru;
+      UInt32 m_num_entries;
+      UInt32 m_tag_bitwidth;
+
+   };
+
+   // Pentium M-specific indexing and tag values
+   void gen_index_tag(IntPtr ip, UInt32& index, UInt32 &tag)
+   {
+      index = (ip >> 6) & 0x1FF;
+      tag = ip & 0x3F;
+   }
+
+   UInt64 m_lru_use_count;
+   UInt32 m_num_ways;
+   std::vector<Way> m_ways;
+
+};
+
+#endif /* GLOBAL_PREDICTOR_H */
diff --git a/common/tile/core/branch_predictors/lpb.h b/common/tile/core/branch_predictors/lpb.h
new file mode 100644
index 0000000..426ed5a
--- /dev/null
+++ b/common/tile/core/branch_predictors/lpb.h
@@ -0,0 +1,344 @@
+//
+// lpb.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef LOOP_BRANCH_PREDICTOR_H
+#define LOOP_BRANCH_PREDICTOR_H
+
+#include <vector>
+#include <stdint.h>
+
+#include "simulator.h"
+#include "branch_predictor.h"
+#include "branch_predictor_return_value.h"
+#include "saturating_predictor.h"
+
+#define DEBUG 0
+
+#if DEBUG == 0
+# define debug_cout if (0) std::cout
+#else
+# define debug_cout std::cout
+#endif
+
+class LoopBranchPredictor
+{
+
+public:
+
+   LoopBranchPredictor(UInt32 entries, UInt32 tag_bitwidth, UInt32 ways)
+      : m_lru_use_count(0)
+      , m_num_ways(ways)
+      , m_ways(ways, Way(entries/ways, tag_bitwidth))
+   {
+   }
+
+   // Not sure if predicted can be used
+   //  it comes from a higher hierarchy
+   //  our predictor isn't valid for this implementation
+   bool predict(IntPtr ip, IntPtr target)
+   {
+      // A IP => predictor is undefined for the LPB because it provides both a hit and prediction
+      // (prediction is only valid when there is a hit)
+      return false;
+   }
+   BranchPredictorReturnValue lookup(IntPtr ip, IntPtr target)
+   {
+
+      UInt32 index, tag;
+      BranchPredictorReturnValue ret = { 0, 0, 0, BranchPredictorReturnValue::InvalidBranch };
+
+      gen_index_tag(ip, index, tag);
+
+      for (unsigned int w = 0 ; w < m_num_ways ; ++w )
+      {
+         // When we are enabled, and we hit, we can use the value even if the count isn't set to the limit
+         if ( m_ways[w].m_enabled[index]
+           && m_ways[w].m_tags[index] == tag )
+         {
+            UInt32 count = m_ways[w].m_count[index];
+            UInt32 limit = m_ways[w].m_limit[index];
+
+            ret.hit = 1;
+            // 000001 -> predict() == 0; 111110 -> predict() == 1
+            if (count == limit)
+            {
+               ret.prediction = ! m_ways[w].m_predictors[index].predict();
+            }
+            else
+            {
+               ret.prediction = m_ways[w].m_predictors[index].predict();
+            }
+            // Save the lru data
+            m_ways[w].m_lru[index] = m_lru_use_count++;
+            break;
+         }
+      }
+
+      return ret;
+   }
+
+   // 000001 -> predict() == 0; 111110 -> predict() == 1
+   void update(bool predicted, bool actual, IntPtr ip, IntPtr target)
+   {
+
+      UInt32 index, tag, lru_way;
+
+      gen_index_tag(ip, index, tag);
+
+      // Start with way 0 as the least recently used
+      lru_way = 0;
+
+      for (UInt32 w = 0 ; w < m_num_ways ; ++w )
+      {
+         if (m_ways[w].m_tags[index] == tag)
+         {
+
+            bool current_prediction = m_ways[w].m_predictors[index].predict();
+            bool match = prediction_match(w, index, actual);
+            bool previous_actual = m_ways[w].m_previous_actual[index];
+            UInt32 &next_counter = m_ways[w].m_count[index];
+            UInt32 &next_limit = m_ways[w].m_limit[index];
+            uint8_t &next_enabled = m_ways[w].m_enabled[index];
+            UInt32 current_counter = next_counter;
+            UInt32 current_limit = next_limit;
+            uint8_t current_enabled = next_enabled;
+
+            // First, determine the control logic for when we are moving in the same direction
+            //  When we see a change, update the limit and reset the counter
+            //  If we are changing our prediction (000001 to 111110), this logic won't work,
+            //   and will be overwritten by the additional logic below
+
+            UInt32 same_direction_counter;
+            UInt32 same_direction_limit;
+            uint8_t same_direction_enabled = next_enabled;
+
+            // Update the limit if we have mismatched
+            if ( ! match )
+            {
+               // Always update the counter on a mismatch
+
+               debug_cout << "[SAME-DIRECTION] Mismatch detected" << std::endl;
+
+               // If the new loop length is now shorter, update the limit with the new counter (loop length)
+               // Reset the counter because we are starting a new loop
+               if (current_counter < current_limit)
+               {
+                  debug_cout << "[SAME-DIRECTION] Mismatch: Shorter loop found" << std::endl;
+
+                  same_direction_counter = 0;
+                  same_direction_limit = current_counter;
+               }
+               // Otherwise, the loop length is now longer, increment the counter and the limit
+               // Do not reset the counter yet
+               // Since this loop is now longer, we should match sometime in the future
+               else
+               {
+                  same_direction_counter = current_counter + 1;
+                  same_direction_limit = current_counter + 1;
+                  same_direction_enabled = 0;
+
+                  debug_cout << "[SAME-DIRECTION] Mismatch: Longer loop found [C:L] [" << current_counter << ":" << current_limit << "] => [" << same_direction_counter << ":" << same_direction_limit << "]" << std::endl;
+               }
+            }
+            else
+            {
+               debug_cout << "[SAME-DIRECTION] Match detected" << std::endl;
+
+               // On a match, we can continue as normal
+               // Update the counter, and nothing else
+               // If we have reached the limit, reset the counter
+               if (current_counter == current_limit)
+                  same_direction_counter = 0;
+               else
+                  same_direction_counter = current_counter + 1;
+
+               // The limit will remain the same
+               same_direction_limit = current_limit;
+            }
+
+            // Determine if we have changed our state
+            // This happens when we have seen two branches both as either taken or not-taken,
+            //  and that this branch status was different than the type predicted.
+            //  000001 -> predict() == 0; 111110 -> predict() == 1
+            //  Example: For the 000001 case (0), we do not expect to see two 1's in a row.
+            if (previous_actual == actual && actual == !current_prediction)
+            {
+
+               debug_cout << "[CHANGE-DIRECTION] Detected!" << std::endl;
+
+               // Here, we have seen two of the opposite type in a row
+               // Reset the limit and the counter for the next pass
+               // We assume that the two predictions seen here are not part of the same branch
+               //  structure, but of two seperate branch structures, and therefore count it as one loop
+               //  iteration instead of two
+               next_counter = 1;
+               next_limit = 1;
+
+               // Update the predictor
+               //  For the 000001 (0) case, and we've seen two 1's, set the predictor to (1), ie. 111110
+               m_ways[w].m_predictors[index].update(actual);
+
+               // Disable the entry since we have just started to look in another direction
+               next_enabled = false;
+            }
+            else
+            {
+
+               debug_cout << "[NO-CHANGE-DIR] Not Detected!" << std::endl;
+
+               // Determine if we should enable this prediction entry
+               // This should happen when we first see a string of branches
+               //  and then have one in the opposite direction
+               //  and we are following our current prediction direction
+               // This situation is also seen in the normal same-direction
+               //  processing.  If that is the case, continue as normal
+               // Therefore, only reset the counters if we are not currently
+               //  enabled.  Already enabled branches should continue as they are
+               if (previous_actual != actual && actual == !current_prediction)
+               {
+                  if (! current_enabled)
+                  {
+                     debug_cout << "[NO-CHANGE-DIR] Enabling entry" << std::endl;
+                     next_enabled = true;
+                     // At the same time, setup the count and limits correctly
+                     next_counter = 0;
+                     next_limit = current_limit;
+                  }
+                  else
+                  {
+                     debug_cout << "[NO-CHANGE-DIR] Entry already enabled" << std::endl;
+
+                     // Here, we haven't see a direction change.
+                     // Use the state from the previous, same direction, section
+                     next_enabled = same_direction_enabled;
+                     next_counter = same_direction_counter;
+                     next_limit = same_direction_limit;
+
+                  }
+               }
+               else
+               {
+               // We are continuing along the normal prediction path, simply update with the next state
+
+                  debug_cout << "[NO-CHANGE-DIR] Updating entry with same direction [C:L] [" << current_counter << ":" << current_limit << "] => [" << same_direction_counter << ":" << same_direction_limit << "]" << std::endl;
+
+                  // Here, we haven't see a direction change.
+                  // Use the state from the previous, same direction, section
+                  next_enabled = same_direction_enabled;
+                  next_counter = same_direction_counter;
+                  next_limit = same_direction_limit;
+
+               }
+
+               // Do not update the actual predictor, since we are moving in the same loop direction
+            }
+
+
+            // Update state and LRU for our next branch
+            m_ways[w].m_previous_actual[index] = actual;
+            m_ways[w].m_lru[index] = m_lru_use_count++;
+            // Once we have a tag match and have updated the LRU information,
+            // we can return
+            return;
+         }
+
+         // Keep track of the LRU in case we do not have a tag match
+         if (m_ways[w].m_lru[index] < m_ways[lru_way].m_lru[index])
+         {
+            lru_way = w;
+         }
+      }
+
+      // We will get here only if we have not matched the tag
+      // If that is the case, select the LRU entry, and update the tag
+      // appropriately
+      m_ways[lru_way].m_tags[index] = tag;
+      // Here, we miss with the tag, so reset instead of updating
+      m_ways[lru_way].m_predictors[index].reset(actual);
+      m_ways[lru_way].m_previous_actual[index] = actual;
+      m_ways[lru_way].m_lru[index] = m_lru_use_count++;
+      m_ways[lru_way].m_count[index] = 1;
+      m_ways[lru_way].m_limit[index] = 1;
+
+   }
+
+private:
+
+   class Way
+   {
+   public:
+
+      Way(UInt32 entries, UInt32 tag_bitwidth)
+         : m_tags(entries, 0)
+         , m_previous_actual(entries, 0)
+         , m_enabled(entries, 0)
+         , m_predictors(entries, SaturatingPredictor<1>(0))
+         , m_lru(entries, 0)
+         , m_count(entries, 0)
+         , m_limit(entries, 0)
+         , m_num_entries(entries)
+         , m_tag_bitwidth(tag_bitwidth)
+      {
+         assert(tag_bitwidth <= 8 && tag_bitwidth >= 0);
+      }
+
+      std::vector<uint8_t> m_tags;
+      std::vector<uint8_t> m_previous_actual;
+      std::vector<uint8_t> m_enabled;
+      std::vector<SaturatingPredictor<1> > m_predictors;
+      std::vector<UInt64> m_lru;
+      std::vector<UInt32> m_count;
+      std::vector<UInt32> m_limit;
+      UInt32 m_num_entries;
+      UInt32 m_tag_bitwidth;
+
+   };
+
+   // Pentium M-specific indexing and tag values
+   void gen_index_tag(IntPtr ip, UInt32& index, UInt32 &tag)
+   {
+      index = (ip >> 4) & 0x3F;
+      tag = (ip >> 10) & 0x3F;
+   }
+
+   // 000001 -> predict() == 0; 111110 -> predict() == 1
+   inline bool prediction_match(UInt32 way, UInt32 index, bool actual)
+   {
+
+      bool prediction = m_ways[way].m_predictors[index].predict();
+      UInt32 count = m_ways[way].m_count[index];
+      UInt32 limit = m_ways[way].m_limit[index];
+
+      // At our count limit
+      if (count == limit)
+      {
+         // Did we predict correctly?
+         if (prediction != actual)
+         {
+            debug_cout << "[PRED-MATCH] Predicted the Loop taken/not-taken limit" << std::endl;
+            return true;
+         }
+         else
+            return false;
+      }
+      // Not at our count limit
+      else
+      {
+         // Did we predict correctly?
+         if (prediction == actual)
+            return true;
+         else
+            return false;
+      }
+   }
+
+   UInt64 m_lru_use_count;
+   UInt32 m_num_ways;
+   std::vector<Way> m_ways;
+
+};
+
+#endif /* LOOP_BRANCH_PREDICTOR_H */
diff --git a/common/tile/core/branch_predictors/pentium_m_bimodal_table.h b/common/tile/core/branch_predictors/pentium_m_bimodal_table.h
new file mode 100644
index 0000000..a28dd92
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_bimodal_table.h
@@ -0,0 +1,28 @@
+//
+// pentium_m_bimodal_table.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef PENTIUM_M_BIMODAL_TABLE
+#define PENTIUM_M_BIMODAL_TABLE
+
+#include "simple_bimodal_table.h"
+
+class PentiumMBimodalTable
+   : public SimpleBimodalTable
+{
+
+public:
+
+   // The Pentium M Global Branch Predictor
+   // 512-entries
+   // 6 tag bits per entry
+   // 4-way set associative
+   PentiumMBimodalTable()
+      : SimpleBimodalTable(4096)
+   {}
+
+};
+
+#endif /* PENTIUM_M_BIMODAL_TABLE */
diff --git a/common/tile/core/branch_predictors/pentium_m_branch_predictor.cc b/common/tile/core/branch_predictors/pentium_m_branch_predictor.cc
new file mode 100644
index 0000000..44d996f
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_branch_predictor.cc
@@ -0,0 +1,95 @@
+//
+// pentium_m_branch_predictor.cc
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#include "simulator.h"
+#include "pentium_m_branch_predictor.h"
+
+PentiumMBranchPredictor::PentiumMBranchPredictor()
+   : m_pir(0)
+{
+}
+
+PentiumMBranchPredictor::~PentiumMBranchPredictor()
+{
+}
+
+bool PentiumMBranchPredictor::predict(IntPtr ip, IntPtr target)
+{
+   IntPtr hash = hash_function(ip, m_pir);
+
+   BranchPredictorReturnValue global_pred_out = m_global_predictor.lookup(hash, target);
+   BranchPredictorReturnValue btb_out = m_btb.lookup(ip, target);
+   BranchPredictorReturnValue lpb_out = m_lpb.lookup(ip, target);
+   bool bimodal_out = m_bimodal_table.predict(ip, target);
+
+   // Outcome prediction logic
+   bool result;
+   if (global_pred_out.hit)
+   {
+      result = global_pred_out.prediction;
+   }
+   else if (lpb_out.hit & btb_out.hit)
+   {
+      result = lpb_out.prediction;
+   }
+   else
+   {
+      result = bimodal_out;
+   }
+
+   // TODO FIXME: Failed matches against the target address should force a branch or fetch miss
+
+   return result;
+}
+
+void PentiumMBranchPredictor::update(bool predicted, bool actual, IntPtr ip, IntPtr target)
+{
+   IntPtr hash = hash_function(ip, m_pir);
+
+   updateCounters(predicted, actual);
+   m_global_predictor.update(predicted, actual, hash, target);
+   m_btb.update(predicted, actual, ip, target);
+   m_lpb.update(predicted, actual, ip, target);
+   m_bimodal_table.update(predicted, actual, ip, target);
+   // TODO FIXME: Properly propagate the branch type information from the decoder (IndirectBranch information)
+   update_pir(actual, ip, target, BranchPredictorReturnValue::ConditionalBranch);
+}
+
+void PentiumMBranchPredictor::outputSummary(std::ostream &os)
+{
+   BranchPredictor::outputSummary(os);
+   os << "    type: pentium_m" << std::endl;
+}
+
+void PentiumMBranchPredictor::update_pir(bool actual, IntPtr ip, IntPtr target, BranchPredictorReturnValue::BranchType branch_type)
+{
+   IntPtr rhs;
+
+   if ((branch_type == BranchPredictorReturnValue::ConditionalBranch) & actual)
+   {
+      rhs = ip >> 4;
+   }
+   else if (branch_type == BranchPredictorReturnValue::IndirectBranch)
+   {
+      rhs = (ip >> 4) | target;
+   }
+   else
+   {
+      rhs = 0;
+   }
+
+   m_pir = (m_pir << 2) ^ rhs;
+}
+
+IntPtr PentiumMBranchPredictor::hash_function(IntPtr ip, IntPtr pir)
+{
+
+   IntPtr top = ((ip >> 13) ^ (pir)) & 0x3F;
+   IntPtr bottom = ((ip >> 4) ^ (pir >> 6)) & 0x1FF;
+
+   return ((top << 9) | bottom);
+}
+
diff --git a/common/tile/core/branch_predictors/pentium_m_branch_predictor.h b/common/tile/core/branch_predictors/pentium_m_branch_predictor.h
new file mode 100644
index 0000000..cc3fbb9
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_branch_predictor.h
@@ -0,0 +1,45 @@
+//
+// pentium_m_branch_predictor.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef PENTIUM_M_BRANCH_PREDICTOR_H
+#define PENTIUM_M_BRANCH_PREDICTOR_H
+
+#include "branch_predictor.h"
+#include "branch_predictor_return_value.h"
+#include "pentium_m_global_predictor.h"
+#include "pentium_m_branch_target_buffer.h"
+#include "pentium_m_bimodal_table.h"
+#include "pentium_m_loop_branch_predictor.h"
+
+#include <vector>
+
+class PentiumMBranchPredictor : public BranchPredictor
+{
+public:
+   PentiumMBranchPredictor();
+   ~PentiumMBranchPredictor();
+
+   bool predict(IntPtr ip, IntPtr target);
+
+   void update(bool predicted, bool actual, IntPtr ip, IntPtr target);
+
+   void outputSummary(std::ostream &os);
+
+private:
+
+   void update_pir(bool actual, IntPtr ip, IntPtr target, BranchPredictorReturnValue::BranchType branch_type);
+   IntPtr hash_function(IntPtr ip, IntPtr pir);
+
+   PentiumMGlobalPredictor m_global_predictor;
+   PentiumMBranchTargetBuffer m_btb;
+   PentiumMBimodalTable m_bimodal_table;
+   PentiumMLoopBranchPredictor m_lpb;
+
+   IntPtr m_pir;
+
+};
+
+#endif
diff --git a/common/tile/core/branch_predictors/pentium_m_branch_target_buffer.h b/common/tile/core/branch_predictors/pentium_m_branch_target_buffer.h
new file mode 100644
index 0000000..d4cdccd
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_branch_target_buffer.h
@@ -0,0 +1,106 @@
+//
+// pentium_m_branch_target_buffer.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef PENTIUM_M_BRANCH_TARGET_BUFFER_H
+#define PENTIUM_M_BRANCH_TARGET_BUFFER_H
+
+#include <vector>
+
+#include "branch_predictor.h"
+
+#define NUM_WAYS 4
+#define NUM_ENTRIES 512
+
+class PentiumMBranchTargetBuffer : BranchPredictor
+{
+   #define IP_TO_INDEX(_ip) ((_ip >> 4) & 0x1ff)
+
+   #define TAG_OFFSET_MASK 0x3fe00f
+   #define IP_TO_TAGOFF(_ip) (_ip & TAG_OFFSET_MASK)
+   // offset = ip[3:0] (4 bits)
+   // index = ip[12:4] (9 bits), 512 entries
+   // tag = ip[21:13] (9 bits)
+   class Way
+   {
+   public:
+      Way()
+         : m_tag_offset(NUM_ENTRIES, 0)
+         , m_plru(NUM_ENTRIES, 0)
+      {}
+
+      std::vector<UInt32> m_tag_offset; // tag and offset data
+      std::vector<UInt64> m_plru; // Should be pseudo-LRU, using LRU instead
+   };
+
+public:
+   PentiumMBranchTargetBuffer()
+      : m_ways(NUM_WAYS)
+      , m_lru_use_count(0)
+   {}
+
+   bool predict(IntPtr ip, IntPtr target)
+   {
+      return false;
+   }
+
+   BranchPredictorReturnValue lookup(IntPtr ip, IntPtr target)
+   {
+      bool hit = false;
+      UInt32 tag_offset = IP_TO_TAGOFF(ip);
+      UInt32 index = IP_TO_INDEX(ip);
+      for (UInt32 i = 0 ; i < NUM_WAYS ; i++)
+      {
+         if (m_ways[i].m_tag_offset[index] == tag_offset)
+         {
+            hit = true;
+            break;
+         }
+      }
+
+      BranchPredictorReturnValue ret = { false, hit, 0, BranchPredictorReturnValue::InvalidBranch };
+
+      return ret;
+   }
+
+   void update(bool predicted, bool actual, IntPtr ip, IntPtr target)
+   {
+      // Start with way 0 as the least recently used
+      UInt32 lru_way = 0;
+
+      UInt32 tag_offset = IP_TO_TAGOFF(ip);
+      UInt32 index = IP_TO_INDEX(ip);
+      for (unsigned int w = 0 ; w < NUM_WAYS ; ++w )
+      {
+         if (m_ways[w].m_tag_offset[index] == tag_offset)
+         {
+            m_ways[w].m_plru[index] = m_lru_use_count++;
+            // Once we have a tag match and have updated the LRU information,
+            // we can return
+            return;
+         }
+
+         // Keep track of the LRU in case we do not have a tag match
+         if (m_ways[w].m_plru[index] < m_ways[lru_way].m_plru[index])
+         {
+            lru_way = w;
+         }
+      }
+
+      // We will get here only if we have not matched the tag
+      // If that is the case, select the LRU entry, and update the tag
+      // appropriately
+      m_ways[lru_way].m_tag_offset[index] = tag_offset;
+      m_ways[lru_way].m_plru[index] = m_lru_use_count++;
+   }
+
+private:
+   std::vector<Way> m_ways;
+   UInt64 m_lru_use_count;
+
+};
+
+#endif /* PENTIUM_M_BRANCH_TARGET_BUFFER_H */
+
diff --git a/common/tile/core/branch_predictors/pentium_m_global_predictor.h b/common/tile/core/branch_predictors/pentium_m_global_predictor.h
new file mode 100644
index 0000000..518f1f9
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_global_predictor.h
@@ -0,0 +1,28 @@
+//
+// pentium_m_global_predictor.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef PENTIUM_M_GLOBAL_PREDICTOR
+#define PENTIUM_M_GLOBAL_PREDICTOR
+
+#include "global_predictor.h"
+
+class PentiumMGlobalPredictor
+   : public GlobalPredictor
+{
+
+public:
+
+   // The Pentium M Global Branch Predictor
+   // 512-entries
+   // 6 tag bits per entry
+   // 4-way set associative
+   PentiumMGlobalPredictor()
+      : GlobalPredictor(2048, 6, 4)
+   {}
+
+};
+
+#endif /* PENTIUM_M_GLOBAL_PREDICTOR */
diff --git a/common/tile/core/branch_predictors/pentium_m_loop_branch_predictor.h b/common/tile/core/branch_predictors/pentium_m_loop_branch_predictor.h
new file mode 100644
index 0000000..2cf7902
--- /dev/null
+++ b/common/tile/core/branch_predictors/pentium_m_loop_branch_predictor.h
@@ -0,0 +1,26 @@
+//
+// pentium_m_loop_branch_predictor.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef PENTIUM_M_LOOP_BRANCH_PREDICTOR
+#define PENTIUM_M_LOOP_BRANCH_PREDICTOR
+
+#include "lpb.h"
+
+class PentiumMLoopBranchPredictor : public LoopBranchPredictor
+{
+
+public:
+
+   // 128 entries
+   // 6 bit tag
+   // 2 ways
+   PentiumMLoopBranchPredictor()
+      : LoopBranchPredictor(128, 6, 2)
+   {}
+
+};
+
+#endif /* PENTIUM_M_LOOP_BRANCH_PREDICTOR */
diff --git a/common/tile/core/branch_predictors/saturating_predictor.h b/common/tile/core/branch_predictors/saturating_predictor.h
new file mode 100644
index 0000000..60fa0b0
--- /dev/null
+++ b/common/tile/core/branch_predictors/saturating_predictor.h
@@ -0,0 +1,112 @@
+//
+// saturating_predictor.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef SATURATING_PREDICTOR_H
+#define SATURATING_PREDICTOR_H
+
+#include <stdint.h>
+#include "fixed_types.h"
+
+// From http://www.josuttis.com/tmplbook/meta/pow3.hpp.html
+template <int N> class Pow2
+{
+public:
+   enum { pow = 2 * Pow2<N-1>::pow };
+};
+
+template <> class Pow2<0>
+{
+public:
+   enum { pow = 1 };
+};
+
+#define SAT_PRED_DEBUG 0
+
+template <unsigned n>
+class SaturatingPredictor {
+
+public:
+
+   SaturatingPredictor(UInt32 initial_value)
+   {
+      m_counter = initial_value;
+   }
+
+   bool predict()
+   {
+      return (m_counter >= 0);
+   }
+
+   void reset(bool prediction = 0)
+   {
+      if (prediction)
+      {
+         // Make this counter favor taken slightly
+         m_counter = 0;
+      }
+      else
+      {
+         // Make this counter favor not-taken slightly
+         m_counter = -1;
+      }
+   }
+
+   // update
+   // true - branch taken
+   // false - branch not-taken
+   void update(bool actual)
+   {
+      if (actual)
+      {
+         // Move towards taken
+         ++(*this);
+      }
+      else
+      {
+         // Move towards not-taken
+         --(*this);
+      }
+   }
+
+   SaturatingPredictor& operator++()
+   {
+#if SAT_PRED_DEBUG
+      cout << "operator++ called! Old val = " << (int) m_counter;
+#endif
+      // Maximum signed value for n bits is (2^(n-1)-1)
+      if (m_counter != (Pow2<n-1>::pow - 1))
+      {
+         ++m_counter;
+      }
+#if SAT_PRED_DEBUG
+      cout << " New val = " << (int) m_counter << endl;
+#endif
+      return *this;
+   }
+
+   SaturatingPredictor& operator--()
+   {
+#if SAT_PRED_DEBUG
+      cout << "operator-- called! Old val = " << (int) m_counter;
+#endif
+      // Minimum signed value for n bits is -(2^(n-1))
+      if (m_counter != (-Pow2<n-1>::pow))
+      {
+         --m_counter;
+      }
+#if SAT_PRED_DEBUG
+      cout << " New val = " << (int) m_counter << endl;
+#endif
+      return *this;
+   }
+
+private:
+
+   int8_t m_counter;
+
+};
+
+#endif /* SATURATING_PREDICTOR_H */
diff --git a/common/tile/core/branch_predictors/simple_bimodal_table.h b/common/tile/core/branch_predictors/simple_bimodal_table.h
new file mode 100644
index 0000000..151603b
--- /dev/null
+++ b/common/tile/core/branch_predictors/simple_bimodal_table.h
@@ -0,0 +1,76 @@
+//
+// simple_bimodal_table.h
+//
+// Copyright (C) 2011 Trevor E. Carlson
+//
+
+#ifndef BIMODAL_TABLE_H
+#define BIMODAL_TABLE_H
+
+#include <boost/scoped_array.hpp>
+#include "simulator.h"
+#include "branch_predictor.h"
+#include "saturating_predictor.h"
+
+class SimpleBimodalTable : BranchPredictor
+{
+
+public:
+
+   SimpleBimodalTable(UInt32 entries)
+      : m_num_entries(entries)
+      , m_table(entries, 0)
+   {
+      reset();
+      m_mask = 0;
+      for (unsigned int i = 0 ; i < ilog2(m_num_entries) ; i++)
+      {
+         m_mask |= (1L<<i);
+      }
+   }
+
+   bool predict(IntPtr ip, IntPtr target)
+   {
+      UInt32 index = ip & m_mask;
+      return (m_table[index].predict());
+   }
+
+   void update(bool predicted, bool actual, IntPtr ip, IntPtr target)
+   {
+      UInt32 index = ip & m_mask;
+      if (actual)
+      {
+         ++m_table[index];
+      }
+      else
+      {
+         --m_table[index];
+      }
+   }
+
+   void reset()
+   {
+      for (unsigned int i = 0 ; i < m_num_entries ; i++) {
+         m_table[i].reset();
+      }
+   }
+
+private:
+
+   template<typename Addr>
+   Addr ilog2(Addr n)
+   {
+      Addr i;
+      for(i=0;n>0;n>>=1,i++);
+      return i-1;
+   }
+
+private:
+
+   UInt32 m_num_entries;
+   IntPtr m_mask;
+   std::vector<SaturatingPredictor<2> > m_table;
+
+};
+
+#endif /* BIMODAL_TABLE_H */
